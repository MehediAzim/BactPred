# -*- coding: utf-8 -*-
"""Model_C.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v2JOZdACeacW5kl5DBMEgLMfAXrrkyMf
"""

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# %cd 'drive/My Drive/Research/Antimicrobial_peptide/code'

# Commented out IPython magic to ensure Python compatibility.
# %ls

# Deep Neural Networks:
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import (Input, Dense, Dropout, Flatten, BatchNormalization,
                                     Conv1D, Conv2D, MaxPooling1D, MaxPooling2D,
                                     LSTM, GRU, Embedding, Bidirectional, Concatenate)
from tensorflow.keras.regularizers import (l1, l2, l1_l2)
from tensorflow.keras.optimizers import (RMSprop, Adam, SGD)
from tensorflow.keras.models import (Sequential, Model)

# Core:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Performance:
from sklearn.metrics import (confusion_matrix, classification_report, matthews_corrcoef, precision_score)
from sklearn.model_selection import (StratifiedKFold, KFold, train_test_split)

#Utilities:
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.utils import to_categorical as labelEncoding   # Usages: Y = labelEncoding(Y, dtype=int)
from tensorflow.keras.utils import plot_model                        # Usages: plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False, expand_nested=True)
from sklearn import preprocessing # Feature Scaling

from sklearn.metrics import average_precision_score
from sklearn.metrics import plot_precision_recall_curve
#end-import

def lossPlot(results):
    plt.title(label='Loss: Training and Validation')
    plt.plot(results.history['loss'], label='Training Loss')
    plt.plot(results.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()
#end-def

def accuracyPlot(results):
    plt.title(label='Accuracy: Training and Validation')
    plt.plot(results.history['accuracy'], label='Training Accuracy')
    plt.plot(results.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()
#end-def

terminus_length = 100

#if you have three representations, you are going to have threee heads and so on
# X1 = np.load("primarySPIDER.npy")
X2 = np.load("antimicrobial_pssm.npy")
# X3 = np.load("bpf.npy")
# X4 = np.load("Primary_physico_31.npy")
#X_train_three = np.load("/content/drive/My Drive/Colab Notebooks/kmer_k_3_ACP240_PCA_20.npy")


# X1 = X1[:,0:terminus_length,0:]
X2 = X2[:,0:terminus_length,0:]
# X3 = X3[:,0:terminus_length,0:]
# X4 = X4[:,0:terminus_length,0:]

# #if you have three representations, you are going to have threee heads and so on
# X1_ind = np.load("IndependentSPIDER.npy")
# X2_ind = np.load("independentPSSM.npy")
# X3_ind = np.load("Bacteriocin_independent_bpf.npy")
# #X_train_three = np.load("/content/drive/My Drive/Colab Notebooks/kmer_k_3_ACP240_PCA_20.npy")


# X1_ind = X1_ind[:,0:terminus_length,0:]
# X2_ind = X2_ind[:,0:terminus_length,0:]
# X3_ind = X3_ind[:,0:terminus_length,0:]


#Make y
Y = list(np.ones(346))
Y[346:692]= np.zeros(346)
Y = np.array(Y)


# print("Maximum Value in SPIDER Encoding: {}".format(np.amax(X1)))

#normalize SPIDER head values

# X1[:,:,0] = X1[:,:,0] / 180
# X1[:,:,1] = X1[:,:,1] / 180
# X1[:,:,2] = X1[:,:,2] / 180
# X1[:,:,3] = X1[:,:,3] / 180
# X1[:,:,4] = X1[:,:,4] / 180 

# for peptide in X1:
#   for amino_acid in peptide:
#     max_property_value = np.amax(amino_acid)
#     if max_property_value > 10:
#       print(amino_acid)

# print(X1.shape)
print(X2.shape)
# print(X4.shape)

print(Y.shape)

def Network():

    branch_one_dense_outputs = []
    branch_two_dense_outputs = []

    ### Head-1:
    input1 = Input(shape=X2[0].shape)

    x = Conv1D(filters=25, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.03))(input1)
    temp_B = Dropout(rate=0.25)(x)
    x = Dropout(rate=0.65)(x)
    temp_A = x

    #Type A feature connection
    dense_output_from_branch_one_filters_combined_one = Dense(units = 20, activation=tf.nn.relu)(Flatten()(temp_A))
    
    #Type B feature connection
    #temp = MaxPooling1D(pool_size=2,strides=2)(temp)
    for filter_index in range(temp_B.shape[-1]):
      i = 0
      branch_one_dense_outputs.append(Dense(units = 2,activation=tf.nn.relu)(temp_B[:,:,filter_index]))


    x = Conv1D(filters=50, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.03))(x)
    temp_B = Dropout(rate=0.25)(x)
    x = Dropout(rate=0.65)(x)
    temp_A = x

    #Type A feature connection
    dense_output_from_branch_one_filters_combined_two = Dense(units = 20, activation=tf.nn.relu)(Flatten()(temp_A))
    
    #Type B feature connection
    #temp = MaxPooling1D(pool_size=2,strides=2)(temp)
    for filter_index in range(temp_B.shape[-1]):
      branch_one_dense_outputs.append(Dense(units = 2,activation=tf.nn.relu)(temp_B[:,:,filter_index]))


    # ### Head-2:
    # input2 = Input(shape=X4[0].shape)

    # x = Conv1D(filters=25, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.03))(input2)
    # temp_B = Dropout(rate=0.25)(x)
    # x = Dropout(rate=0.65)(x)
    # temp_A = x

    # #Type A feature connection
    # dense_output_from_branch_two_filters_combined_one = Dense(units = 20, activation=tf.nn.relu)(Flatten()(temp_A))
    
    # #Type B feature connection
    # #temp = MaxPooling1D(pool_size=2,strides=2)(temp)
    # for filter_index in range(temp_B.shape[-1]):
    #   i = 0
    #   branch_two_dense_outputs.append(Dense(units = 2,activation=tf.nn.relu)(temp_B[:,:,filter_index]))


    # x = Conv1D(filters=50, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.03))(x)
    # temp_B = Dropout(rate=0.25)(x)
    # x = Dropout(rate=0.65)(x)
    # temp_A = x

    # #Type A feature connection
    # dense_output_from_branch_two_filters_combined_two = Dense(units = 20, activation=tf.nn.relu)(Flatten()(temp_A))
    
    # #Type B feature connection
    # #temp = MaxPooling1D(pool_size=2,strides=2)(temp)
    # for filter_index in range(temp_B.shape[-1]):
    #   branch_two_dense_outputs.append(Dense(units = 2,activation=tf.nn.relu)(temp_B[:,:,filter_index]))


    #Type B feature connection
    branch_one_dense_outputs = Concatenate()(branch_one_dense_outputs)
    # branch_one_dense_outputs = Dropout(rate=0.45)(branch_one_dense_outputs)
    # branch_one_dense_outputs = Dense(units = 20, activation=tf.nn.relu)(branch_one_dense_outputs)

    # branch_two_dense_outputs = Concatenate()(branch_two_dense_outputs)
    # # branch_two_dense_outputs = Dropout(rate=0.45)(branch_two_dense_outputs)
    # # branch_two_dense_outputs = Dense(units = 20, activation=tf.nn.relu)(branch_two_dense_outputs)



    # merge = Concatenate()([branch_one_dense_outputs,
    #                        branch_two_dense_outputs])

    output = Dropout(rate=0.50)(branch_one_dense_outputs)

    output = Dense(units=1, activation='sigmoid')(output)

    return Model(inputs=[input1], outputs=output)
#end-def

model = Network()
# model.summary()
# plot_model(model, to_file='model-240.png', show_shapes=True, show_layer_names=False, expand_nested=True)

def calculate_performance(test_num, pred_y, labels):
    tp = 0
    fp = 0
    tn = 0
    fn = 0
    for index in range(test_num):
        if labels[index] == 1:
            if labels[index] == pred_y[index]:
                tp = tp + 1
            else:
                fn = fn + 1
        else:
            if labels[index] == pred_y[index]:
                tn = tn + 1
            else:
                fp = fp + 1

    # entering any of the else statement means that the evaluation etric is invalid
    acc = float(tp + tn) / test_num
    
    if((tp + fp) != 0):
      precision = float(tp) / (tp + fp)
    else:
      precision = 0

    if((tp + fp) != 0):
      sensitivity = float(tp) / (tp + fn)
    else:
      sensitivity = 0

    if((tn + fp) != 0):
      specificity = float(tn) / (tn + fp)
    else:
      specificity = 0

    MCC = float(tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))
    F1 = 2 * (precision * sensitivity) / (precision + sensitivity)
    return acc, precision, sensitivity, specificity, MCC , F1

learning_rate = 0.00019

kf =  StratifiedKFold(n_splits = 5,shuffle=True)

all_accuracies = []
all_acc = []
all_precision = []
all_sensitivity = []
all_specificity = []
all_MCC = []
all_F1 = []

prob = []
all_apur = []
result=[]
 
#lrate = LearningRateScheduler(step_decay)

callbacks_list = []

epoch_value = 200

for train_index,test_index in kf.split(X2,Y):
    
    model = Network()

    optimizer = Adam(lr=learning_rate)

    model.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=['accuracy'])

    # result.append(model.fit(x=[X_train_one[train_index,:,0:terminus_length]],y=y_train[train_index],validation_data=([X_train_one[test_index,:,0:terminus_length]],y_train[test_index]), epochs=epoch_value, batch_size=15))                                                  
    result.append(model.fit(x=[X2[train_index,:,:]],y=Y[train_index],validation_data=([X2[test_index,:,:]],Y[test_index]), epochs=epoch_value, batch_size=15,callbacks=callbacks_list))
    
    # scores = model.evaluate([X_train_one[test_index,:,:],X_train_two[test_index,:,:],X_train_three[test_index,:,:]], y_train[test_index], verbose=0)
    scores = model.evaluate([X2[test_index,:,:]], Y[test_index], verbose=0)
    # scores = model.evaluate([X_train_one[test_index,:,:]], y_train[test_index], verbose=0)

    # probabilities = model.predict([X_train_one[test_index,:,:],X_train_two[test_index,:,:],X_train_three[test_index,:,:]])
    probabilities = model.predict([X2[test_index,:,:]])
    # probabilities = model.predict([X_train_one[test_index,:,:]])

    prob.extend(list(probabilities))
    predicted_classes = probabilities >= 0.5
    
    all_apur.append(average_precision_score(Y[test_index], probabilities))
    
    predicted_classes = predicted_classes.astype(int)

    acc, precision, sensitivity, specificity, MCC, F1 = calculate_performance(len(test_index), predicted_classes, Y[test_index])

    all_accuracies.append(scores)
    all_acc.append(acc)
    all_MCC.append(MCC)
    all_F1.append(F1)
    if(sensitivity != 0):
      all_sensitivity.append(sensitivity)
    if(specificity != 0):
      all_specificity.append(specificity)
    if(precision != 0):
      all_precision.append(precision)

total_accuracy = 0
for i in range(5) :
    loss,accuracy = all_accuracies[i]
    #print(accuracy)
    total_accuracy = total_accuracy + accuracy


for i in range(5):
  print('fold -',i,'accuracy',all_acc[i])

print('accuracy',sum(all_acc)/5, end =", ")
print('MCC',sum(all_MCC)/5, end =", ")
print('precision',sum(all_precision)/5, end =", ")
print('sensitivity',sum(all_sensitivity)/5, end =", ")
print('specificity',sum(all_specificity)/5, end =", ")
print('f1 score',sum(all_F1)/5)

print(np.sum((np.array(prob)>0.95).astype(int)),"sequence has a probability of more than 95%")
print("AUPR score :- ",sum(all_apur)/5)

print("Model specification")
print("pssm")
print("Epoch\t",str(epoch_value),"\tLearning rate \t"+str(learning_rate))

# def loss_plot(result):
#   fig=plt.figure(figsize=(25,12))
#   columns = 5
#   rows = 2

#   for i in range(len(result)):
#       fig.add_subplot(rows, columns, i+1)
#       plt.title(label='Loss: Training and Validation')
#       plt.plot(result[i].history['loss'], label='loss')
#       plt.plot(result[i].history['val_loss'], label='val_loss')
#       plt.xlabel('Epoch - '+str(i+1))
#       plt.ylabel('Loss')
#       plt.legend()  
#   plt.show()
# def accuracy_plot(result):
#     fig=plt.figure(figsize=(25,12))
#     columns = 5
#     rows = 2 
#     for i in range(len(result)):
#       fig.add_subplot(rows, columns, i+1)   
#       plt.title(label='Accuracy: Training and Validation')
#       plt.plot(result[i].history['accuracy'], label='accuracy')
#       plt.plot(result[i].history['val_accuracy'], label='val_accuracy')
#       plt.xlabel('Epoch - '+str(i+1))
#       plt.ylabel('Accuracy')
#       plt.legend()
#     plt.show()

# #ploting the figures
# loss_plot(result)
# accuracy_plot(result)

print("done!!!")