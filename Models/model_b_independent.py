# -*- coding: utf-8 -*-
"""Model_B_Independent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lp42NVpRP6Kwdn5evXDLqxcf46W6vEXS
"""

# from google.colab import drive
# drive.mount('/content/drive',force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# %cd 'drive/My Drive/Research/Antimicrobial_peptide/code'

# Commented out IPython magic to ensure Python compatibility.
# %ls

# Deep Neural Networks:
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import (Input, Dense, Dropout, Flatten, BatchNormalization,
                                     Conv1D, Conv2D, MaxPooling1D, MaxPooling2D,
                                     LSTM, GRU, Embedding, Bidirectional, Concatenate)
from tensorflow.keras.regularizers import (l1, l2, l1_l2)
from tensorflow.keras.optimizers import (RMSprop, Adam, SGD)
from tensorflow.keras.models import (Sequential, Model)

# Core:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Performance:
from sklearn.metrics import (confusion_matrix, classification_report, matthews_corrcoef, precision_score)
from sklearn.model_selection import (StratifiedKFold, KFold, train_test_split)

#Utilities:
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.utils import to_categorical as labelEncoding   # Usages: Y = labelEncoding(Y, dtype=int)
from tensorflow.keras.utils import plot_model                        # Usages: plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False, expand_nested=True)
from sklearn import preprocessing # Feature Scaling

from sklearn.metrics import average_precision_score
from sklearn.metrics import plot_precision_recall_curve
#end-import

terminus_length = 100

#if you have three representations, you are going to have threee heads and so on
# X1 = np.load("primarySPIDER.npy")
X2 = np.load("antimicrobial_pssm.npy")
# X3 = np.load("bpf.npy")
X4 = np.load("Primary_physico_31.npy")
#X_train_three = np.load("/content/drive/My Drive/Colab Notebooks/kmer_k_3_ACP240_PCA_20.npy")


# X1 = X1[:,0:terminus_length,0:]
X2 = X2[:,0:terminus_length,0:]
# X3 = X3[:,0:terminus_length,0:]
X4 = X4[:,0:terminus_length,0:]

# #if you have three representations, you are going to have threee heads and so on
X1_ind = np.load("independentPSSM.npy")
X2_ind = np.load("bacteriocin_independent_physico_31.npy")
# X3_ind = np.load("Bacteriocin_independent_bpf.npy")
# #X_train_three = np.load("/content/drive/My Drive/Colab Notebooks/kmer_k_3_ACP240_PCA_20.npy")


X1_ind = X1_ind[:,0:terminus_length,0:]
X2_ind = X2_ind[:,0:terminus_length,0:]
# X3_ind = X3_ind[:,0:terminus_length,0:]


#Make y
Y = list(np.ones(346))
Y[346:692]= np.zeros(346)
Y = np.array(Y)

y_test = list(np.ones(74))
y_test[74:]= np.zeros(74)
y_test = np.array(y_test)


# print(X1.shape)
print(X2.shape)
print(X4.shape)

print(Y.shape)

print(y_test.shape)

def Network():

    branch_one_dense_outputs = []
    branch_two_dense_outputs = []

    ### Head-1:
    input1 = Input(shape=X2[0].shape)

    x = Conv1D(filters=25, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.03))(input1)
    temp_B = Dropout(rate=0.25)(x)
    x = Dropout(rate=0.65)(x)
    temp_A = x

    #Type A feature connection
    dense_output_from_branch_one_filters_combined_one = Dense(units = 20, activation=tf.nn.relu)(Flatten()(temp_A))
    
    #Type B feature connection
    #temp = MaxPooling1D(pool_size=2,strides=2)(temp)
    for filter_index in range(temp_B.shape[-1]):
      i = 0
      branch_one_dense_outputs.append(Dense(units = 2,activation=tf.nn.relu)(temp_B[:,:,filter_index]))


    x = Conv1D(filters=50, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.03))(x)
    temp_B = Dropout(rate=0.25)(x)
    x = Dropout(rate=0.65)(x)
    temp_A = x

    #Type A feature connection
    dense_output_from_branch_one_filters_combined_two = Dense(units = 20, activation=tf.nn.relu)(Flatten()(temp_A))
    
    #Type B feature connection
    #temp = MaxPooling1D(pool_size=2,strides=2)(temp)
    for filter_index in range(temp_B.shape[-1]):
      branch_one_dense_outputs.append(Dense(units = 2,activation=tf.nn.relu)(temp_B[:,:,filter_index]))


    ### Head-2:
    input2 = Input(shape=X4[0].shape)

    x = Conv1D(filters=25, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.03))(input2)
    temp_B = Dropout(rate=0.25)(x)
    x = Dropout(rate=0.65)(x)
    temp_A = x

    #Type A feature connection
    dense_output_from_branch_two_filters_combined_one = Dense(units = 20, activation=tf.nn.relu)(Flatten()(temp_A))
    
    #Type B feature connection
    #temp = MaxPooling1D(pool_size=2,strides=2)(temp)
    for filter_index in range(temp_B.shape[-1]):
      i = 0
      branch_two_dense_outputs.append(Dense(units = 2,activation=tf.nn.relu)(temp_B[:,:,filter_index]))


    x = Conv1D(filters=50, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.03))(x)
    temp_B = Dropout(rate=0.25)(x)
    x = Dropout(rate=0.65)(x)
    temp_A = x

    #Type A feature connection
    dense_output_from_branch_two_filters_combined_two = Dense(units = 20, activation=tf.nn.relu)(Flatten()(temp_A))
    
    #Type B feature connection
    #temp = MaxPooling1D(pool_size=2,strides=2)(temp)
    for filter_index in range(temp_B.shape[-1]):
      branch_two_dense_outputs.append(Dense(units = 2,activation=tf.nn.relu)(temp_B[:,:,filter_index]))


    #Type B feature connection
    branch_one_dense_outputs = Concatenate()(branch_one_dense_outputs)
    # branch_one_dense_outputs = Dropout(rate=0.45)(branch_one_dense_outputs)
    # branch_one_dense_outputs = Dense(units = 20, activation=tf.nn.relu)(branch_one_dense_outputs)

    branch_two_dense_outputs = Concatenate()(branch_two_dense_outputs)
    # branch_two_dense_outputs = Dropout(rate=0.45)(branch_two_dense_outputs)
    # branch_two_dense_outputs = Dense(units = 20, activation=tf.nn.relu)(branch_two_dense_outputs)



    merge = Concatenate()([branch_one_dense_outputs,
                           branch_two_dense_outputs])

    output = Dropout(rate=0.50)(merge)

    output = Dense(units=1, activation='sigmoid')(output)

    return Model(inputs=[input1, input2], outputs=output)
#end-def

model = Network()
# model.summary()
# plot_model(model, to_file='model-240.png', show_shapes=True, show_layer_names=False, expand_nested=True)

def calculate_performance(test_num, pred_y, labels):
    tp = 0
    fp = 0
    tn = 0
    fn = 0
    for index in range(test_num):
        if labels[index] == 1:
            if labels[index] == pred_y[index]:
                tp = tp + 1
            else:
                fn = fn + 1
        else:
            if labels[index] == pred_y[index]:
                tn = tn + 1
            else:
                fp = fp + 1

    # entering any of the else statement means that the evaluation etric is invalid
    acc = float(tp + tn) / test_num
    
    if((tp + fp) != 0):
      precision = float(tp) / (tp + fp)
    else:
      precision = 0

    if((tp + fp) != 0):
      sensitivity = float(tp) / (tp + fn)
    else:
      sensitivity = 0

    if((tn + fp) != 0):
      specificity = float(tn) / (tn + fp)
    else:
      specificity = 0

    MCC = float(tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))
    F1 = 2 * (precision * sensitivity) / (precision + sensitivity)
    return acc, precision, sensitivity, specificity, MCC , F1

#Training model
epoch_value = 200
learning_rate = 0.00019
model = Network()
optimizer = Adam(lr=learning_rate)

model.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=['accuracy'])
model.fit(x=[X2[:,:,:],X4[:,:,:]],y=Y, epochs=epoch_value, batch_size=15)

scores = model.evaluate([X1_ind[:,:,:],X2_ind[:,:,:]], y_test, verbose=0)
probabilities = model.predict([X1_ind[:,:,:],X2_ind[:,:,:]])


prob = list(probabilities)
predicted_classes = probabilities >= 0.5
    
aupr = average_precision_score(y_test , probabilities)
    
predicted_classes = predicted_classes.astype(int)

acc, precision, sensitivity, specificity, MCC , F1 = calculate_performance(len(y_test), predicted_classes, y_test)

print('accuracy',acc, end =", ")
print('MCC',MCC, end =", ")
print('precision',precision, end =", ")
print('sensitivity',sensitivity, end =", ")
print('specificity',specificity)
print(np.sum((np.array(prob)>0.95).astype(int)),"sequence has probability more than 95%")
print("AUPR score :- ",aupr)

print("Model specification")
print("Epoch\t",str(epoch_value),"\tLearning rate \t"+str(learning_rate))

print("done!!!")